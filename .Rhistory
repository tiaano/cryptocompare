title= "Different Insurance bands")
sup_filter <- "umsu"
df_loans_fin %>% inner_join(df_top_sup)  %>% #View()
sample_frac(0.1) %>%
mutate(highlight = ifelse(grepl(sup_filter,tolower(SUPPLIER_NAME)),SUPPLIER_NAME,"OTHER")) %>%
arrange(desc(highlight)) %>%
filter(clipt <= 20) %>%
ggplot(aes(x=OPEN_BAL_VALUE, y = clipt2,col = highlight,alpha = highlight)) +
geom_point(aes(size=PMNT_TERM_VALUE)) +
scale_color_manual(values =  c("blue","grey")) +
scale_alpha_manual(values = c(1,0.5))+
labs(x = "Opening Balance",
y = "R Insurance/R1000)",
title= "Different Insurance bands")
df_loans_fin %>% inner_join(df_top_sup)  %>% #View()
sample_frac(0.1) %>%
filter(clipt <= 20) %>%
ggplot(aes(x=OPEN_BAL_VALUE, y = clipt2,col = SUPPLIER_NAME)) +
geom_point(aes(size=PMNT_TERM_VALUE)) +
labs(x = "Opening Balance",
y = "R Insurance/R1000)",
title= "Different Insurance bands")
df_loans_fin %>% View()
library(tidyverse)
library(odbc)
setwd("C:/Users/c16672a/Projects/Data Management/CI/Automation Processes/Load Report Extract")
df_loans_fin
library(FinCal)
library(DBI)
library(tidyverse)
library(odbc)
df_loans <- readRDS("c:/Users/c16672a/Projects/Data Management/SBSA/cli.rds")
#  NCA Max values
v_max_fee <- 69
v_max_init <- 1207.5
v_rate <- 0.26
# Values for run
v_max_fee <- 69
v_max_init <- 1207.5
v_rate <- 0.26
# v_base_pmt <- -1*FinCal::pmt(r = (v_rate/12),n = v_terms, pv = v_open_bal,fv = 0)
# v_max_pmt <- v_base_pmt +  v_max_fee + (v_max_init / v_terms)
df_loans_fin <- df_loans %>%
mutate(
# Calculate the installment based on known values
base_pmt = -1*FinCal::pmt(r = (v_rate/12),n = PMNT_TERM_VALUE, pv = OPEN_BAL_VALUE,fv = 0),
# Calculate the installment including init fee
base_pmt_incl_init = -1*FinCal::pmt(r = (v_rate/12),n = PMNT_TERM_VALUE, pv = OPEN_BAL_VALUE+v_max_init,fv = 0),
# Add fees to installment
max_pmt = base_pmt +  v_max_fee + (v_max_init / PMNT_TERM_VALUE),
max_pmt_incl_init = base_pmt_incl_init + v_max_fee,
# Credit Life Ins: Where Act Installment > Maximum calculated installment
cli = ifelse(INST_AMT_VALUE > max_pmt,INST_AMT_VALUE - max_pmt,0),
cli2 = ifelse(INST_AMT_VALUE > max_pmt_incl_init,INST_AMT_VALUE - max_pmt_incl_init,0),
# Credit Life Ins: per thousand
clipt = round(cli/floor(OPEN_BAL_VALUE/1000),2),
clipt2 = round(cli2/floor(OPEN_BAL_VALUE/1000),2)) %>%
filter(!is.na(clipt) & clipt != 0 & is.finite(clipt) &
CURR_BAL_VALUE <= OPEN_BAL_VALUE) %>%
select(-base_pmt)
df_top_sup <- df_loans_fin %>% count(SUPPLIER_NAME) %>% arrange(desc(n)) %>%
head(10)
library(readxl)
library(rstudioapi)
library(DBI)
library(odbc)
library(dplyr)
lx_file <- "//xbfp/Central/Tiaan/CI_Data_Validation/Load_Reports/Source Files/Book1.xlsx"
load_conf <- read_xlsx(lx_file)
load_conf$`HEADER DATE` <- as.integer(format(load_conf$`HEADER DATE`,"%Y%m%d"))
load_conf$`RECORDS RECEIVED` <- as.integer(load_conf$`RECORDS RECEIVED`)
con <- DBI::dbConnect(odbc::odbc(),"DM_REPORTING",UID = "mpi_interface",
PWD = rstudioapi::askForPassword("Database password"))
# DBI::dbWriteTable(con, "#tempGO", load_conf[,c(1,2,5)])
dbWriteTable(con,"##tempGO",load_conf[,c(1,2,5)])
#dbCreateTable(con,"#tempGO",load_conf[,c(1,2,5)],temporary = T)
target_folder <- "\\\\xbfp\\Central\\Tiaan\\CI_Data_Validation\\Load_Reports\\Esme\\Monthly\\"
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Raw_Load_Report_",File_Identifier,".pdf"), new_target = paste0(target_folder,SRN,"_",File_Header_Date,".pdf")) %>% select(new_source, new_target)
copy_success_list <- file.copy(from = file_copy_list$new_source,to = file_copy_list$new_target)
copy_success_list
library(readxl)
library(rstudioapi)
library(DBI)
library(odbc)
library(dplyr)
lx_file <- "//xbfp/Central/Tiaan/CI_Data_Validation/Load_Reports/Source Files/Book1.xlsx"
load_conf <- read_xlsx(lx_file)
load_conf$`HEADER DATE` <- as.integer(format(load_conf$`HEADER DATE`,"%Y%m%d"))
load_conf$`RECORDS RECEIVED` <- as.integer(load_conf$`RECORDS RECEIVED`)
con <- DBI::dbConnect(odbc::odbc(),"DM_REPORTING",UID = "mpi_interface",
PWD = rstudioapi::askForPassword("Database password"))
# DBI::dbWriteTable(con, "#tempGO", load_conf[,c(1,2,5)])
dbWriteTable(con,"##tempGO",load_conf[,c(1,2,5)])
#dbCreateTable(con,"#tempGO",load_conf[,c(1,2,5)],temporary = T)
target_folder <- "\\\\xbfp\\Central\\Tiaan\\CI_Data_Validation\\Load_Reports\\Esme\\Monthly\\"
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Raw_Load_Report_",File_Identifier,".pdf"), new_target = paste0(target_folder,SRN,"_",File_Header_Date,".pdf")) %>% select(new_source, new_target)
copy_success_list <- file.copy(from = file_copy_list$new_source,to = file_copy_list$new_target)
copy_success_list
library(tidyverse)
library(rstudioapi)
library(readxl)
library(odbc)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
par_source_path <- "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-20"
par_source_file <- "ABSA_Trans_Master_Activities_1May_to_31Aug2018"
par_source_type <- ".csv" # ".csv" ".txt"
par_source_delimeter <- "," # does not matter if type is xlsx
par_source_IDNum_column <- "ID_NUMBER" # case sensitive
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
# source_file_filter <- showPrompt(title = "File type",message = "What is the source file's file type? (e.g. csv, xlsx, txt)",default = "csv")
#
# source_file_filter <- paste0("*.",source_file_filter)
#
# source_file_path <- selectFile(path = "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/MiWayLife/2018/Data Delivered",filter = source_file_filter)
source_data <- tibble()
if (par_source_type %in% c("*.xlsx","*.xls")) {
source_data <- read_excel(path = source_file_name,col_types = "text")
}
# {
#  source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0)
}
source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0, n_max = 10)
View(source_data)
par_source_path <- "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-20"
#Example: "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-03/Current clients"
par_source_file <- "ABSA_Trans_Master_Activities_1May_to_31Aug2018"
#Example: "RETAIL_PREMIUM_FINAL_WITH_ID"
par_source_type <- ".csv" # ".csv" ".txt"
par_source_delimeter <- "," # does not matter if type is xlsx
par_source_IDNum_column <- "LEAD ID" # case sensitive
library(tidyverse)
library(rstudioapi)
library(readxl)
library(odbc)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
source_data <- tibble()
if (par_source_type %in% c("*.xlsx","*.xls")) {
source_data <- read_excel(path = source_file_name,col_types = "text")
} else {
source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0)
}
head(source_data)
con_mos <- dbConnect(odbc(),"NZSQL") #<-- NZSQL should be a system odbc on your local system, connecting to EXPERIAN_MOSAIC
source_data <- source_data %>% rename(ID_NUMBER = par_source_IDNum_column)
par_source_IDNum_column <- "Lead ID" # case sensitive
source_data <- source_data %>% rename(ID_NUMBER = par_source_IDNum_column)
colnames(source_data) <- gsub(" ","_",toupper(colnames(source_data)))
dbSendQuery(con_mos,"DROP TABLE SOURCE_DATA_AUTO_MOSAIC_MAPPING IF EXISTS")
dbWriteTable(conn = con_mos, name = "SOURCE_DATA_AUTO_MOSAIC_MAPPING",value = source_data)
dbSendQuery(con_mos,"DROP TABLE SOURCE_DATA_AUTO_MOSAIC_MAPPING IF EXISTS")
#Total records
nrow(source_mosaic)
group_color <- scale_fill_manual(values=c("#8C78B8", "#804460", "#E87D0D","#71BF44","#4FB5CC","#CC47CC","#AD1F26","#857819","#228F6B","#999999"))
source_mosaic %>% group_by(GROUP_CODE) %>% summarise(GROUP_COUNT = n()) %>% ggplot(mapping = aes(GROUP_CODE,GROUP_COUNT,fill = GROUP_CODE)) + geom_col()  + group_color
source_mosaic %>% group_by(GROUP_CODE, TYPE_CODE) %>% summarise(TYPE_COUNT = n()) %>% ggplot(mapping = aes(TYPE_CODE,TYPE_COUNT,fill = GROUP_CODE)) + geom_col() + group_color
par_output_path <- par_source_path # or other path if you so choose
par_output_file <- "Mosaic_Mapped.csv"
source_mosaic %>% write_delim(path = paste0(par_output_path,"/",par_output_file),delim = ",",col_names = T)
library(DBI)
library(odbc)
nz_con <- dbConnect(odbc(),"NZ_BLG2")
df_loans <- dbGetQuery(nz_con,"SELECT
HEAD024,
SUPPLIER_NUMBER,
SUPPLIER_NAME,
ACCT_TYPE_CODE,
OPEN_BAL_VALUE::int4 OPEN_BAL_VALUE,
CURR_BAL_VALUE::int4 CURR_BAL_VALUE,
OPEN_DATE_VALUE,
INST_AMT_VALUE::int4 INST_AMT_VALUE,
PMNT_TERM_VALUE::int4 PMNT_TERM_VALUE,
LAST_PAY_DATE_VALUE,
CURR_BAL_DATE_VALUE,
STATUS_CODE,
MONTHS_IN_ARREARS
FROM
ADMIN.SB_SAMPLE_ACCOUNTS
WHERE
ACCT_TYPE_CODE = '1' AND
PMNT_TERM_VALUE::int4 > 2 AND
CURR_BAL_VALUE::int4 <> 0
AND
OVERD_AMT_VALUE::int4 = 0 AND
substr(OPEN_DATE_VALUE,1,6) >= '201801'
AND length(translate(MONTHS_IN_ARREARS,'?0','')) = 0")
library(DBI)
nz_con <- dbConnect(odbc(),"NZSQL")
library(odbc)
nz_con <- dbConnect(odbc(),"NZSQL")
dbSendQuery(nz_con,"groom table EXPERIAN_CUBE.ADMIN.SBSA_PL_08 VERSIONS;")
View(df_groom)
dbDisconnect(nz_con)
nz_con <- dbConnect(odbc(),"NZ_ADMIN")
View(df_groom)
fn_groom_auto <- function(db_name,sch_name,tbl_name){
qry_switch_db <- paste("SET CATALOG",db_name)
qry_groom_table <- paste("groom table",sch_name,".",tbl_name,"VERSIONS;")
dbSendQuery(nz_con,qry_switch_db)
dbSendQuery(nz_con,qry_groom_table)
}
df_groom_list <- df_groom[,1:3]
View(df_groom_list)
seq_along(df_groom_list)
fn_test <- function(v1,v2,v3){
print(v1)
print(v2)
print(v3)
}
fn_test("p1","p2","p3")
l1 <- c("p1-1","p1-2","p1-3")
l2 <- c("p2-1","p2-2","p2-3")
l3 <- c("p3-1","p3-2","p3-3")
fn_test(l1,l2,l3)
apply(l1, fn_test, v2 = l2, v3 = l3)
df_test <- as.data.frame(c1 = l1,c2 = l2, c3 = l3)
df_test <- data.frame(c1 = l1,c2 = l2, c3 = l3)
View(df_test)
apply(df_test,MARGIN = 1,FUN = fn_test, v2 = c2, v3 = c3)
apply(df_test,MARGIN = 2,FUN = fn_test, v2 = c2, v3 = c3)
apply(df_test,MARGIN = 2,FUN = fn_test)
apply(df_test,MARGIN = 2,FUN = fn_test, v2 = df_test$c2, v3 = df_test$c3)
df_test <- data.frame(c1 = l1,c2 = l2, c3 = l3,stringsAsFactors = F)
apply(df_test,MARGIN = 2,FUN = fn_test, v2 = df_test$c2, v3 = df_test$c3)
Map(fn_test,df_test$c1,df_test$c2,df_test$c3)
no_ret <- Map(fn_test,df_test$c1,df_test$c2,df_test$c3)
NULL <- Map(fn_test,df_test$c1,df_test$c2,df_test$c3)
fn_groom_auto <- function(db_name,sch_name,tbl_name){
qry_switch_db <- paste("SET CATALOG",db_name)
qry_groom_table <- paste("groom table",sch_name,".",tbl_name,"VERSIONS;")
dbSendQuery(nz_con,qry_switch_db)
print(paste("Execute:",qry_groom_table))
dbSendQuery(nz_con,qry_groom_table)
print("Done")
}
df_groom_list <- df_groom[,1:3]
no_ret <- Map(fn_groom_auto,df_groom_list$DATABASE,df_groom_list$SCHEMA,df_groom_list$TABLENAME)
fn_groom_auto <- function(db_name,sch_name,tbl_name){
qry_switch_db <- paste("SET CATALOG",db_name)
qry_groom_table <- paste0("groom table ",sch_name,".",tbl_name," VERSIONS;")
dbSendQuery(nz_con,qry_switch_db)
print(paste("Execute:",qry_groom_table))
dbSendQuery(nz_con,qry_groom_table)
print("Done")
}
fn_groom_auto <- function(db_name,sch_name,tbl_name){
qry_switch_db <- paste("SET CATALOG",db_name)
qry_groom_table <- paste0("groom table ",sch_name,".",tbl_name," VERSIONS;")
print("-----------------------")
dbSendQuery(nz_con,qry_switch_db)
print(paste("Execute:",qry_groom_table))
dbSendQuery(nz_con,qry_groom_table)
print("Done")
}
df_groom_list <- df_groom[,1:3]
no_ret <- Map(fn_groom_auto,df_groom_list$DATABASE,df_groom_list$SCHEMA,df_groom_list$TABLENAME)
length(df_groom)
length(df_groom)
length(df_groom)
nrow(df_groom)
dbDisconnect(nz_con)
library(tidyverse)
library(sp)
library(sf)
library(spatialEco)
library(rstudioapi)
nc <- st_read("shapefiles/SA_EACode_Poly.shp")
# plot(head(nc,100))
file_name <- rstudioapi::selectFile(filter = c("*.csv"))
geo_file_raw <- read_delim(file_name,delim = "|",guess_max = 0)
geo_file <- filter(geo_file_raw,!is.na(geo_file$displayLatitude))
geo_file <- filter(geo_file_raw,!is.na(geo_file$displayLatitude))
geo_file <- filter(geo_file_raw,!is.na(geo_file_raw$displayLatitude))
geo_file$displayLatitude <- as.double(geo_file$displayLatitude)
geo_file$displayLongitude <- as.double(geo_file$displayLongitude)
my.sf.point <- st_as_sf(x = geo_file,
coords = c("displayLongitude", "displayLatitude"),
crs = "+proj=longlat +datum=WGS84")
point_with_ea <- point.in.poly(my.sf.point,nc)
class(point_with_ea)
class(as_tibble(point_with_ea))
head(point_with_ea)
dir_path <- rstudioapi::selectDirectory()
file_name_out <- "Combined_OO_Mosaic_SA201809_eacode.csv"
join_points <- as_tibble(point_with_ea) %>% select(RecordID,EA_CODE)
geo_file_raw %>% left_join(join_points,by = "RecordID")  %>% write_delim(path = paste(dir_path,file_name_out,sep = "/"),delim = "|",col_names = T)
library(tidyverse)
library(rstudioapi)
library(readxl)
library(odbc)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
par_source_path <- "file://xbfp/Work/Decision Analytics/Marketing_Solutions/Projects/One and Only Resorts/2018/4 Data/Working Files"
#Example: "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-03/Current clients"
par_source_file <- "Combined_OO_Mosaic_SA201809_eacode"
#Example: "RETAIL_PREMIUM_FINAL_WITH_ID"
par_source_type <- ".csv" # ".csv" ".txt"
par_source_delimeter <- "," # does not matter if type is xlsx
par_source_IDNum_column <- "Lead ID" # case sensitive
# -------------------------------------------------
par_output_path <- par_source_path # or other path if you so choose
par_output_file <- "Mosaic_Mapped.csv"
library(tidyverse)
library(rstudioapi)
library(readxl)
library(odbc)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
source_data <- tibble()
if (par_source_type %in% c("*.xlsx","*.xls")) {
source_data <- read_excel(path = source_file_name,col_types = "text")
} else {
source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0)
}
source_file_name
par_source_path <- "//xbfp/Work/Decision Analytics/Marketing_Solutions/Projects/One and Only Resorts/2018/4 Data/Working Files"
#Example: "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-03/Current clients"
par_source_file <- "Combined_OO_Mosaic_SA201809_eacode"
#Example: "RETAIL_PREMIUM_FINAL_WITH_ID"
par_source_type <- ".csv" # ".csv" ".txt"
par_source_delimeter <- "," # does not matter if type is xlsx
par_source_IDNum_column <- "Lead ID" # case sensitive
# -------------------------------------------------
par_output_path <- par_source_path # or other path if you so choose
par_output_file <- "Mosaic_Mapped.csv"
library(tidyverse)
library(rstudioapi)
library(readxl)
library(odbc)
source_file_name <- paste0(par_source_path,"/",par_source_file,par_source_type)
# source_file_filter <- showPrompt(title = "File type",message = "What is the source file's file type? (e.g. csv, xlsx, txt)",default = "csv")
#
# source_file_filter <- paste0("*.",source_file_filter)
#
# source_file_path <- selectFile(path = "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/MiWayLife/2018/Data Delivered",filter = source_file_filter)
source_data <- tibble()
if (par_source_type %in% c("*.xlsx","*.xls")) {
source_data <- read_excel(path = source_file_name,col_types = "text")
} else {
source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0)
}
head(source_data)
par_source_path <- "//xbfp/Work/Decision Analytics/Marketing_Solutions/Projects/One and Only Resorts/2018/4 Data/Working Files"
#Example: "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/Absa/2018/Leads/4 Data/Original/2018-09-03/Current clients"
par_source_file <- "Combined_OO_Mosaic_SA201809_eacode"
#Example: "RETAIL_PREMIUM_FINAL_WITH_ID"
par_source_type <- ".csv" # ".csv" ".txt"
par_source_delimeter <- "|" # does not matter if type is xlsx
par_source_IDNum_column <- "Lead ID" # case sensitive
# -------------------------------------------------
par_output_path <- par_source_path # or other path if you so choose
par_output_file <- "Mosaic_Mapped.csv"
# source_file_filter <- showPrompt(title = "File type",message = "What is the source file's file type? (e.g. csv, xlsx, txt)",default = "csv")
#
# source_file_filter <- paste0("*.",source_file_filter)
#
# source_file_path <- selectFile(path = "//XBFP/Work/Decision Analytics/Marketing_Solutions/Projects/MiWayLife/2018/Data Delivered",filter = source_file_filter)
source_data <- tibble()
if (par_source_type %in% c("*.xlsx","*.xls")) {
source_data <- read_excel(path = source_file_name,col_types = "text")
} else {
source_data <- read_delim(source_file_name,delim = par_source_delimeter,guess_max = 0)
}
head(source_data)
par_source_EACode_column <- "EA_CODE" # case sensitive
con_mos <- dbConnect(odbc(),"NZSQL") #<-- NZSQL should be a system odbc on your local system, connecting to EXPERIAN_MOSAIC
source_data <- source_data %>% rename(EA_CODE = par_source_EACode_column)
colnames(source_data) <- gsub(" ","_",toupper(colnames(source_data)))
dbSendQuery(con_mos,"DROP TABLE SOURCE_DATA_AUTO_MOSAIC_MAPPING IF EXISTS")
dbWriteTable(conn = con_mos, name = "SOURCE_DATA_AUTO_MOSAIC_MAPPING",value = source_data)
dbSendQuery(con_mos,"DROP TABLE SOURCE_DATA_AUTO_MOSAIC_MAPPING IF EXISTS")
source_mosaic %>% group_by(GLOBAL_LOOKUP_GROUP) %>% summarise(GROUP_COUNT = n()) %>% ggplot(mapping = aes(GLOBAL_LOOKUP_GROUP,GROUP_COUNT,fill = GLOBAL_LOOKUP_GROUP)) + geom_col()  + group_color
group_color <- scale_fill_manual(values=c("#8C78B8", "#804460", "#E87D0D","#71BF44","#4FB5CC","#CC47CC","#AD1F26","#857819","#228F6B","#999999"))
source_mosaic %>% group_by(GLOBAL_LOOKUP_GROUP) %>% summarise(GROUP_COUNT = n()) %>% ggplot(mapping = aes(GLOBAL_LOOKUP_GROUP,GROUP_COUNT,fill = GLOBAL_LOOKUP_GROUP)) + geom_col()  + group_color
View(source_mosaic)
source_mosaic
source_mosaic[,2:13]
source_mosaic[,(2:13)]
source_mosaic[,c(2:13,29)]
par_output_file <- "Combined_OO_Mosaic_SA201809_Mosaic_Mapped.csv"
source_mosaic[,c(2:13,29)] %>% write_delim(path = paste0(par_output_path,"/",par_output_file),delim = ",",col_names = T)
library(tidyverse)
library(odbc)
setwd("C:/Users/c16672a/Projects/Data Management/CI/Automation Processes/Load Report Extract")
jud_files <- read_delim("Judgment_File_IDs.txt",delim = "\t")
con <- DBI::dbConnect(odbc::odbc(), "CAIS_EVO_SQL01", UID = "mpi_interface",
PWD = rstudioapi::askForPassword("Database password"))
colnames(jud_files) <- c("f_name","f_id")
colnames(jud_files) <- c("f_name","f_id")
dbWriteTable(con,"##tempGO",jud_files)
View(source_files)
paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T)
paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T)
paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Court_Judgement_Report_",f_id,".pdf")
paste0(gsub("d$\\automation\\automation_","",tolower(source_files$File_Processing_Directory),fixed = T),"Court_Judgement_Report_",f_id,".pdf")
paste0(gsub("d$\\automation\\automation_","",tolower(source_files$File_Processing_Directory),fixed = T),"Court_Judgement_Report_",source_files$f_id,".pdf")
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Court_Judgement_Report_",f_id,".pdf"), new_target = paste0(target_folder,gsub(".txt","",f_name),".pdf")) %>% filter(!is.na(File_Processing_Directory)) %>% select(new_source, new_target)
target_folder <- "//xbfp/Central/Tiaan/CI_Data_Validation/Load_Reports/Feroza/"
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Court_Judgement_Report_",f_id,".pdf"), new_target = paste0(target_folder,gsub(".txt","",f_name),".pdf")) %>% filter(!is.na(File_Processing_Directory)) %>% select(new_source, new_target)
file_copy_list
copy_success_list <- file.copy(from = file_copy_list$new_source,to = file_copy_list$new_target)
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Raw_File_",f_id,"_Rejected.log"), new_target = paste0(target_folder,gsub(".txt","",f_name),"_Rejected.log")) %>% filter(!is.na(File_Processing_Directory)) %>% select(new_source, new_target)
copy_success_list <- file.copy(from = file_copy_list$new_source,to = file_copy_list$new_target)
setwd("~/Personal/RProjects/cryptocompare")
library(readxl)
library(httr)
library(jsonlite)
library(dplyr)
library(purrr)
rxls <- read_xlsx("Binance Trading Pairs.xlsx",sheet = "Binance")
rxls <- rxls %>% select(TradeCoin,BaseCoin) %>% mutate(BaseCoin = gsub(pattern = "USDT",replacement = "USD",x = BaseCoin,fixed = T))
itt <- 0
Get_Trade_Info <- function(p_from_sym,p_to_sym) {
itt <<- itt + 1
# Init variables ----
u_base <- "https://min-api.cryptocompare.com/data/histominute"
u_from_sym <- p_from_sym
u_to_sym <- p_to_sym
u_limit <- 2
u_agg <- 1
# Init URL ----
u_tail <- paste("fsym=",u_from_sym,"&tsym=",u_to_sym,"&limit=",u_limit,"&aggregate=",u_agg,"&e=CCCAGG",sep = "")
p_url <- paste(u_base,u_tail,sep="?")
# Call API ----
get_prices <- GET(p_url)
# Get Data ----
get_prices_text <- content(get_prices, "text")
get_prices_json <- fromJSON(get_prices_text, flatten = TRUE)
dt_prices <- as.data.frame(get_prices_json$Data)
# Clean Data ----
dt_prices$CTime <- as.POSIXct(dt_prices$time, origin="1970-01-01")
dt_prices$time <- NULL
dt_prices$from_sym <- u_from_sym
dt_prices$to_sym <- u_to_sym
print(itt)
return(dt_prices)
}
itt <- 0
options(scipen=999)
trade_data <- map2(rxls$TradeCoin,rxls$BaseCoin,Get_Trade_Info)
tbl_trade_data <- bind_rows(trade_data)
tbl_trade_data %>% group_by(from_sym,to_sym) %>% summarise(CTime)
tbl_trade_data %>% group_by(from_sym,to_sym) %>% summarise(MaxTime = max(CTime))
minute_meta <- tbl_trade_data %>% group_by(from_sym,to_sym) %>% summarise(MaxTime = max(CTime)) %>%
write.csv(tbl_trade_data,"/crypto_arch/data/trade_data_min.csv")
minute_meta <- tbl_trade_data %>% group_by(from_sym,to_sym) %>% summarise(MaxTime = max(CTime))
View(minute_meta)
tbl_trade_data_2 <- bind_rows(trade_data)
itt <- 0
options(scipen=999)
trade_data <- map2(rxls$TradeCoin,rxls$BaseCoin,Get_Trade_Info)
tbl_trade_data_2 %>% left_join(minute_meta,by = c(from_sym,to_sym))
View(tbl_trade_data)
tbl_trade_data_2 %>% left_join(minute_meta,by = c(from_sym = from_sym,to_sym = to_sym))
tbl_trade_data_2 %>% left_join(minute_meta,by = c(from_sym = from_sym))
View(tbl_trade_data_2)
tbl_trade_data_2 %>% left_join(minute_meta)
tbl_trade_data_2 %>% left_join(minute_meta,by = c("from_sym", "to_sym")) %>% filter(CTime > MaxTime)
trade_data <- map2(rxls$TradeCoin[1:2],rxls$BaseCoin[1:2],Get_Trade_Info)
tbl_trade_data_2 <- bind_rows(trade_data)
tbl_trade_data_2 %>% left_join(minute_meta,by = c("from_sym", "to_sym")) %>% filter(CTime > MaxTime)
Get_Trade_Info <- function(p_from_sym,p_to_sym) {
itt <<- itt + 1
# Init variables ----
u_base <- "https://min-api.cryptocompare.com/data/histominute"
u_from_sym <- p_from_sym
u_to_sym <- p_to_sym
u_limit <- 2000
u_agg <- 1
# Init URL ----
u_tail <- paste("fsym=",u_from_sym,"&tsym=",u_to_sym,"&limit=",u_limit,"&aggregate=",u_agg,"&e=CCCAGG",sep = "")
p_url <- paste(u_base,u_tail,sep="?")
# Call API ----
get_prices <- GET(p_url)
# Get Data ----
get_prices_text <- content(get_prices, "text")
get_prices_json <- fromJSON(get_prices_text, flatten = TRUE)
dt_prices <- as.data.frame(get_prices_json$Data)
# Clean Data ----
dt_prices$CTime <- as.POSIXct(dt_prices$time, origin="1970-01-01")
dt_prices$time <- NULL
dt_prices$from_sym <- u_from_sym
dt_prices$to_sym <- u_to_sym
print(itt)
Sys.sleep(1)
return(dt_prices)
}
itt <- 0
options(scipen=999)
trade_data <- map2(rxls$TradeCoin[1:2],rxls$BaseCoin[1:2],Get_Trade_Info)
tbl_trade_data_2 %>% left_join(minute_meta,by = c("from_sym", "to_sym")) %>% filter(CTime > MaxTime)
library(readxl)
library(rstudioapi)
library(DBI)
library(odbc)
library(dplyr)
lx_file <- "//xbfp/Central/Tiaan/CI_Data_Validation/Load_Reports/Source Files/Book1.xlsx"
load_conf <- read_xlsx(lx_file)
load_conf$`HEADER DATE` <- as.integer(format(load_conf$`HEADER DATE`,"%Y%m%d"))
load_conf$`RECORDS RECEIVED` <- as.integer(load_conf$`RECORDS RECEIVED`)
con <- DBI::dbConnect(odbc::odbc(),"DM_REPORTING",UID = "mpi_interface",
PWD = rstudioapi::askForPassword("Database password"))
# DBI::dbWriteTable(con, "#tempGO", load_conf[,c(1,2,5)])
dbWriteTable(con,"##tempGO",load_conf[,c(1,2,5)])
#dbCreateTable(con,"#tempGO",load_conf[,c(1,2,5)],temporary = T)
View(source_files)
target_folder <- "\\\\xbfp\\Central\\Tiaan\\CI_Data_Validation\\Load_Reports\\Esme\\Monthly\\"
file_copy_list <- source_files %>% mutate(new_source = paste0(gsub("d$\\automation\\automation_","",tolower(File_Processing_Directory),fixed = T),"Raw_Load_Report_",File_Identifier,".pdf"), new_target = paste0(target_folder,SRN,"_",File_Header_Date,".pdf")) %>% select(new_source, new_target)
copy_success_list <- file.copy(from = file_copy_list$new_source,to = file_copy_list$new_target)
copy_success_list
file_copy_list
file_copy_list[copy_success_list,]
file_copy_list$new_source[copy_success_list]
file_copy_list$new_source[!copy_success_list]
